{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tBCRsHzuwH_B",
    "pycharm": {
     "name": "#%% md\n"
    },
    "tags": [
     "excluded_from_script"
    ]
   },
   "source": [
    "# Machine Learning Project, Task 1: Feature Engineering - Data Visualization\n",
    "\n",
    "Before you start, make sure that you are familiar with the basic usage of Jupyter Notebook. \n",
    "\n",
    "If not, please finish the Jupyter Notebook primer first. Additionally, visit the Azure Notebook library [Cloud Computing Course](https://notebooks.azure.com/CloudComputingCourse/projects/cloud-computing-course) and read the tutorials with **worked examples** and practice on Linux, Bash and Pandas.\n",
    "\n",
    "In this task, you are visualizing spatial and temporal data which would influence cab fare prices in New York City. You need to implement the following methods based on your observations:\n",
    "```\n",
    "q1()\n",
    "q2()\n",
    "q3()\n",
    "q4()\n",
    "```\n",
    "\n",
    "Please do not change any utility method. More cells may be added to the notebook. If you don't want to include the cell in the converted script, please tag the cell with `excluded_from_script`. You can display the tags for each cell as such: `View > Cell Toolbar > Tags`.\n",
    "\n",
    "Execute `./runner.sh` in the console to check the result. Please make sure that the virtualenv is activated when executing `runner.sh`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0nUlxigIwIgC",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Import libraries that q1 - q4 depend on.\n",
    "# Please DO NOT change this cell. \n",
    "# The cell will be included in the converted Python script.\n",
    "import pandas as pd\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "import scipy.signal\n",
    "import sys\n",
    "import argparse\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": [
     "excluded_from_script"
    ]
   },
   "outputs": [],
   "source": [
    "# Import packages that are used in data visualization but not in q1 - q4.\n",
    "# This cell will be excluded in the converted Python script.\n",
    "import seaborn as sns\n",
    "from mapboxgl.utils import *\n",
    "from mapboxgl.viz import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cTuwt-8PwOmf",
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": [
     "excluded_from_script"
    ]
   },
   "outputs": [],
   "source": [
    "def visualize_map(data, center, zoom):\n",
    "    \"\"\"\n",
    "    This is a sample method for you to get used to spatial data visualization using the Mapboxgl-jupyter library.\n",
    "    \n",
    "    Mapboxgl-jupyter is a location based data visualization library for Jupyter Notebooks.\n",
    "    To better understand this, you may want to read the documentation: \n",
    "    https://mapbox-mapboxgl-jupyter.readthedocs-hosted.com/en/latest/\n",
    "    \n",
    "    To use the library, you need to register for a token by accessing: \n",
    "    https://account.mapbox.com/access-tokens/\n",
    "    You need to create an account and login. Then you can see your access token by revisiting the above URL.\n",
    "    \n",
    "    You can check the output of this method by exporting your token as an environment variable `MAPBOX_ACCESS_TOKEN`.\n",
    "    and by executing the cell below. It may take several minutes to show a complete map.\n",
    "    \n",
    "    Hint:\n",
    "    You can set the environment variable in Jupyter Notebook by creating a cell to\n",
    "    execute `os.environ['MAPBOX_ACCESS_TOKEN'] = \"pk.your_specific_token\"`.\n",
    "    Be sure to exclude the plaintext token from your submission \n",
    "    by deleting the cell that includes \n",
    "    `os.environ['MAPBOX_ACCESS_TOKEN'] = \"pk.your_specific_token\"`.\n",
    "    \"\"\"\n",
    "    # Create the viz from the dataframe\n",
    "    viz = CircleViz(data,\n",
    "                    access_token = os.environ['MAPBOX_ACCESS_TOKEN'],\n",
    "                    center = center,\n",
    "                    zoom = zoom,\n",
    "                  )\n",
    "    # It could take several minutes to show the map\n",
    "    print(\"showing map...\")\n",
    "    viz.show();\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eUBr5sMMwPlk",
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": [
     "excluded_from_script"
    ]
   },
   "outputs": [],
   "source": [
    "# set the center of the map\n",
    "center_of_nyc = (-74, 40.73)\n",
    "\n",
    "# visualize an empty map of New York City\n",
    "visualize_map(data=None, center=center_of_nyc, zoom=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Q1: Spatial Data Visualization\n",
    ">In q1, you will explore the geographical distribution of the data.\n",
    "\n",
    ">You should carry out the data visualization and explore the dataset using `cc_nyc_fare_train_small.csv`, the same dataset will be used in the following feature engineering task. However, please use `NA_boundary_box.csv` when submitting q1.\n",
    "\n",
    ">Steps:\n",
    ">1. Find the proper inputs to feed into the `visualize_map` method and visualize the spatial data.\n",
    ">2. Explore the data points on the map. Does every point make sense? Should some data be in the Atlantic Ocean? \n",
    ">3. Implement a data filter to exclude rows with pickup location outside the region of the United States.\n",
    "\n",
    ">Hint: \n",
    "\n",
    ">You may want to figure out latitude and longitude boundaries for the United States excluding the bordering countries. A good place to find a bounding box is: http://boundingbox.klokantech.com/. Please explore the usage of this bounding box tool and find the required bounding box. You may drag and drop the box to include the region you want."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ztalpkf22-vh",
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": [
     "excluded_from_script"
    ]
   },
   "outputs": [],
   "source": [
    "# Create a geojson file export from a Pandas dataframe\n",
    "df = pd.read_csv('data/cc_nyc_fare_train_small.csv', parse_dates=['pickup_datetime'])\n",
    "data = df_to_geojson(df, lat='pickup_latitude', lon='pickup_longitude')\n",
    "\n",
    "# TODO: visualize spatial data on a map\n",
    "raise NotImplementedError(\"To be implemented\")\n",
    "visualize_map(data=data, center=TODO, zoom=TODO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "o71KMM8Q2uL6",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def q1():\n",
    "    \"\"\"\n",
    "    ML Objective: When exploring raw datasets you will often come across data points which do not fit the business \n",
    "    case and are called outliers. In this case, the outliers might denote data points outside of the specific area\n",
    "    since our goal is to develop a model to predict fares in NYC. \n",
    "    \n",
    "    You might want to exclude such data points to make your model perform better in the Feature Engineering Task.\n",
    "    \n",
    "    TODO: Exclude rows with pickup location outside the region of the United States excluding the bordering countries.\n",
    "    \n",
    "    output format:\n",
    "    <row number>, <pickup_longitude>, <pickup_latitude>\n",
    "    <row number>, <pickup_longitude>, <pickup_latitude>\n",
    "    <row number>, <pickup_longitude>, <pickup_latitude>\n",
    "    ...\n",
    "    \"\"\"\n",
    "    \n",
    "    df = pd.read_csv('data/NA_boundary_box.csv').loc[:,['pickup_latitude', 'pickup_longitude']]\n",
    "    \n",
    "    # TODO: Implement a data filter to exclude the data outside the region of the United States\n",
    "    #       (replace \"None\" with your implementation)\n",
    "    raise NotImplementedError(\"To be implemented\")\n",
    "    res = None\n",
    "    \n",
    "    # print the result to standard output in the CSV format\n",
    "    res.to_csv(sys.stdout, encoding='utf-8', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_Hs42-u93Bnl",
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": [
     "excluded_from_script"
    ]
   },
   "outputs": [],
   "source": [
    "q1()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TfkUI9x_wNzq",
    "pycharm": {
     "name": "#%% md\n"
    },
    "tags": [
     "excluded_from_script"
    ]
   },
   "source": [
    "# Q2: Hotspots and Distance\n",
    ">In this task, you are supposed to calculate the distance between Madison Square Garden (MSG) and the most popular pickup location in the southeast of NYC based on your observation of the heatmap.\n",
    "\n",
    ">You are still using `cc_nyc_fare_train_small` for data visualization to get a better idea of the dataset for the feature engineering task.\n",
    "\n",
    ">Hints: \n",
    ">1. To find the southeastern hotspot, you need to call the draw_heatmap method to draw a heatmap. \n",
    ">2. You need to figure out the latitude and longitude of the hotspot you observed and Madison Square Garden. \n",
    ">3. You should use the provided haversine_distance function to calculate the distance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GHEbLvPO5am9",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Utility methods, please do not change.\n",
    "\n",
    "def haversine_distance(origin, destination):\n",
    "    \"\"\"\n",
    "    Formula to calculate the spherical distance between 2 coordinates, with each specified as a (lat, lng) tuple\n",
    "\n",
    "    :param origin: (lat, lng)\n",
    "    :type origin: tuple\n",
    "    :param destination: (lat, lng)\n",
    "    :type destination: tuple\n",
    "    :return: haversine distance\n",
    "    :rtype: float\n",
    "    \"\"\"\n",
    "    lat1, lon1 = origin\n",
    "    lat2, lon2 = destination\n",
    "    radius = 6371  # km\n",
    "\n",
    "    dlat = math.radians(lat2 - lat1)\n",
    "    dlon = math.radians(lon2 - lon1)\n",
    "    a = math.sin(dlat / 2) * math.sin(dlat / 2) + math.cos(math.radians(lat1)) * math.cos(\n",
    "        math.radians(lat2)) * math.sin(dlon / 2) * math.sin(dlon / 2)\n",
    "    c = 2 * math.atan2(math.sqrt(a), math.sqrt(1 - a))\n",
    "    d = radius * c\n",
    "\n",
    "    return d\n",
    "  \n",
    "\n",
    "def draw_heatmap(data, center, zoom):\n",
    "    \"\"\"\n",
    "    Method to draw a heat map. You should use this method to identify the most popular pickup location in the southeast of NYC.\n",
    "\n",
    "    :param geodata: name of GeoJSON file or object or JSON join-data weight_property\n",
    "    :type geodata: string\n",
    "    :param center: map center point\n",
    "    :type center: tuple\n",
    "    :param zoom: starting zoom level for map\n",
    "    :type zoom: float\n",
    "    \"\"\"\n",
    "    # set features for the heatmap\n",
    "    heatmap_color_stops = create_color_stops([0.01,0.25,0.5,0.75,1], colors='RdPu')\n",
    "    heatmap_radius_stops = [[10,1],[20,2]] #increase radius with zoom\n",
    "\n",
    "    # create a heatmap\n",
    "    viz = HeatmapViz(data,\n",
    "                     access_token=os.environ['MAPBOX_ACCESS_TOKEN'],\n",
    "                     color_stops=heatmap_color_stops,\n",
    "                     radius_stops=heatmap_radius_stops,\n",
    "                     height='500px',\n",
    "                     opacity=0.9,\n",
    "                     center=center,\n",
    "                     zoom=zoom)\n",
    "    print(\"drawing map...\")\n",
    "    viz.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zFIQg6u39nI_",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def q2():\n",
    "    \"\"\"\n",
    "    ML Objective: When exploring raw datasets, you will come often across a small set of data points which might \n",
    "    exhibit a unique or different behavior as compared to the rest of the data points. \n",
    "    \n",
    "    In this case, the fare between two hotspots in NYC might be much higher irrespective of the distance between them. \n",
    "    You might want to identify such data points to make your model perform better during the Feature Engineering Task.\n",
    "    \n",
    "    TODO: calculate the distance between MSG and the most popular pickup location in the southeast of NYC.\n",
    "    \n",
    "    output format:\n",
    "    <distance>\n",
    "    \"\"\"\n",
    "   \n",
    "    MSG_coor = (40.750298, -73.993324) # lat, lng\n",
    "    \n",
    "    # TODO: replace \"None\" with your implementation\n",
    "    raise NotImplementedError(\"To be implemented\")\n",
    "    hot_spot_coor = None\n",
    "    res = None\n",
    "    \n",
    "    print(round(res, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "X87-5kVU-mWg",
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": [
     "excluded_from_script"
    ]
   },
   "outputs": [],
   "source": [
    "q2()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qAWfaupfFgbK",
    "pycharm": {
     "name": "#%% md\n"
    },
    "tags": [
     "excluded_from_script"
    ]
   },
   "source": [
    "# Time-related Features\n",
    "\n",
    ">Before conducting feature engineering, you may want to think about time-based features, which could be correlated with traffic conditions that may influence the fare.\n",
    "\n",
    ">In q3, you need to implement the method to extract year, month, hour and weekday from the pickup_datetime feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YAbJS8sZAb9w",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def q3():\n",
    "    \"\"\"\n",
    "    ML Objective: As described above, time based features are crucial for better performance of an ML model since \n",
    "    the input data points often change with respect to time.  \n",
    "    \n",
    "    In this case, the traffic conditions might be higher during office hours or during weekends which may result \n",
    "    in higher fares. You might want to develop such time-based features to make your model perform better during the \n",
    "    Feature Engineering Task.\n",
    "    \n",
    "    TODO: You need to implement the method to extract year, month, hour and weekday from the pickup_datetime feature\n",
    "    \n",
    "    output format:\n",
    "    <row number>, <pickup_datetime>, <fare_amount>, <year>, <month>, <hour>, <weekday>\n",
    "    \"\"\"\n",
    "    # read the CSV file into a DataFrame\n",
    "    df = pd.read_csv('data/cc_nyc_fare_train_tiny.csv', parse_dates=['pickup_datetime'])\n",
    "    time_features = df.loc[:, ['pickup_datetime', 'fare_amount']]\n",
    "\n",
    "    # TODO: extract time-related features from the `pickup_datetime` column.\n",
    "    #       (replace \"None\" with your implementation)\n",
    "    raise NotImplementedError(\"To be implemented\")\n",
    "    time_features['year'] = None\n",
    "    time_features['month'] = None\n",
    "    time_features['hour'] = None\n",
    "    time_features['weekday'] = None\n",
    "    \n",
    "    # print the result to standard output in the CSV format\n",
    "    time_features.to_csv(sys.stdout, encoding='utf-8', header=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EudJHzI_rpht",
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": [
     "excluded_from_script"
    ]
   },
   "outputs": [],
   "source": [
    "q3()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7OmZxxmDUqNC",
    "pycharm": {
     "name": "#%% md\n"
    },
    "tags": [
     "excluded_from_script"
    ]
   },
   "source": [
    "# Q4: Investigate time pattern"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sCpP4nU6UywK",
    "pycharm": {
     "name": "#%% md\n"
    },
    "tags": [
     "excluded_from_script"
    ]
   },
   "source": [
    "In feature engineering, you must write your transformation code to be stateless, which means the transformed features of test set should match the transformed features of the training set. After you have trained your model using transformed features from the training set, you will need to perform the same transformation on the records from the test set with the same code.\n",
    "\n",
    "An example is filtering outliers according to the percentile values of the feature using [pandas.DataFrame.quantile](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.quantile.html). **Calling these functions directly on the training set and test set may probably perform different transformations and yield different results, since each has a different set of records.** It performs the same transformation only if the training set and test set have the same quantile distribution of the numeric column.\n",
    "\n",
    "Instead, you should **store** the unique value of a numeric column from the **training set**, to apply them consistently to the **test set**.\n",
    "\n",
    ">In q4, you are expected to:\n",
    "\n",
    ">1. Use the DataFrame you generated in q3 to visualize the relationship between year, hour, weekday and fare_amount. \n",
    ">2. Explore the plot of year 2013 and fix the abnormal distribution by removing 0.1% of raw data.\n",
    "\n",
    ">You are using `cc_nyc_fare_train_small` as your training set. However, please use `cc_nyc_fare_train_tiny` as your test set in the implementation of q4.\n",
    "\n",
    ">Hint:\n",
    "\n",
    ">1. You may want to draw a histogram to find what is happening here.\n",
    ">2. The method needs to be stateless, i.e., the passed input DataFrame should not be modifed. To achieve this, you may want to find the 99.9% quantile and hardcode the specific number in the filter so that it won't change when you're using test data)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bYozOPVyAcBE",
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": [
     "excluded_from_script"
    ]
   },
   "outputs": [],
   "source": [
    "# Utility method, please do not change.\n",
    "\n",
    "def draw_fare_time_plot(df):\n",
    "    \"\"\"\n",
    "    Utility function to draw a heatmap on fare_amount, weekday, hour and year.\n",
    "    \n",
    "    input format:\n",
    "    <pickup_datetime>, <fare_amount>, <year>, <month>, <hour>, <weekday>\n",
    "    <pickup_datetime>, <fare_amount>, <year>, <month>, <hour>, <weekday>\n",
    "    <pickup_datetime>, <fare_amount>, <year>, <month>, <hour>, <weekday>\n",
    "    ...\n",
    "    \"\"\"\n",
    "    # group data by time-related figures and calculate mean fare amount\n",
    "    df = df.groupby(['year','weekday','hour']).mean().reset_index()\n",
    "    \n",
    "    # plot\n",
    "    plt.figure(1, figsize=(18,10))\n",
    "    for (i, year) in enumerate(range(2009, 2016)):\n",
    "        ax = plt.subplot(2, 4, i + 1)\n",
    "        df_plot = df.query('year == @year') \n",
    "        sns.heatmap(df_plot.pivot(index='hour', columns='weekday', values='fare_amount'), annot=False, cmap=\"Blues\")\n",
    "        plt.title(\"year \" + str(year)) \n",
    "        ax.set(xlim=(-1, 7))\n",
    "        ax.set(ylim=(0, 25))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ya1B_Ub7fuXW",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def q4():\n",
    "    \"\"\"\n",
    "    ML Objective: While relying on time based features might be beneficial, it is a good practice to remove the \n",
    "    abnormalities in the data. \n",
    "    \n",
    "    In this case, the time of the day might not be an explicable factor for the resulting fare. When developing \n",
    "    time-based features you might want to exclude a few abnormal data points which might lead to overfitting.\n",
    "    \n",
    "    Fix the abnormal distribution in `fare_amount` by removing 0.1% of raw data.\n",
    "    \n",
    "    output format:\n",
    "    <row number>, <pickup_datetime>, <fare_amount>\n",
    "    <row number>, <pickup_datetime>, <fare_amount>\n",
    "    <row number>, <pickup_datetime>, <fare_amount>\n",
    "    ...\n",
    "    \"\"\"\n",
    "    # read the CSV file into a DataFrame\n",
    "    df = pd.read_csv('data/cc_nyc_fare_train_tiny.csv', parse_dates=['pickup_datetime']).loc[:, ['pickup_datetime', 'fare_amount']]\n",
    "\n",
    "    # TODO: replace \"None\" with the 99.9% quantile\n",
    "    raise NotImplementedError(\"To be implemented\")\n",
    "    df = df[df['fare_amount'] < None]\n",
    "\n",
    "    # print the result to standard output in the CSV format\n",
    "    df.to_csv(sys.stdout, encoding='utf-8', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Vimlo-hornUD",
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": [
     "excluded_from_script"
    ]
   },
   "outputs": [],
   "source": [
    "q4()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    },
    "tags": [
     "excluded_from_script"
    ]
   },
   "source": [
    "# DO NOT MODIFY ANYTHING BELOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def main():\n",
    "    parser = argparse.ArgumentParser(\n",
    "        description=\"Project Machine Learning on Cloud\")\n",
    "    parser.add_argument(\"-r\",\n",
    "                        metavar='<question_id>',\n",
    "                        required=False)\n",
    "    args = parser.parse_args()\n",
    "    question = args.r\n",
    "\n",
    "    if question == \"q1\":\n",
    "        q1()\n",
    "    elif question == \"q2\":\n",
    "        q2()\n",
    "    elif question == \"q3\":\n",
    "        q3()\n",
    "    elif question == \"q4\":\n",
    "        q4()\n",
    "    else:\n",
    "        print(\"Invalid question\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "colab": {
   "collapsed_sections": [],
   "name": "p4final.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
