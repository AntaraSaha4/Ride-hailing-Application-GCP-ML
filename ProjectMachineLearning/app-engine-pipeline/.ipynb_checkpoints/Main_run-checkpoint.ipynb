{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "4167e4fa-a4ae-43e7-b083-9e622f33c747",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = \"/home/clouduser/ml-fare-prediction-120818-68a160b0f29f.json\"\n",
    "os.environ['GOOGLE_MAPS_API_KEY'] = 'AIzaSyCfGaNV6Sojs_v-uKab0VvI7OfA43jtOpY'\n",
    "os.environ['GOOGLE_CLOUD_PROJECT'] = 'ml-fare-prediction-120818'\n",
    "os.environ['VERTEX_AI_MODEL_ENDPOINT'] = '1892171550472273920'\n",
    "os.environ['LOCATION'] = 'us-east1'\n",
    "os.environ['AUTO_ML_MODEL_ENDPOINT_ID'] = '5716204822156279808'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "ea4e0bd4-174a-4793-a847-3a55727fdd15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__'\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n",
      " * Running on http://127.0.0.1:5000\n",
      "INFO:werkzeug:\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n",
      " * Running on http://127.0.0.1:5000\n",
      "\u001b[33mPress CTRL+C to quit\u001b[0m\n",
      "INFO:werkzeug:\u001b[33mPress CTRL+C to quit\u001b[0m\n",
      "127.0.0.1 - - [05/Dec/2023 05:35:01] \"POST /farePredictionVision HTTP/1.1\" 200 -\n",
      "INFO:werkzeug:127.0.0.1 - - [05/Dec/2023 05:35:01] \"POST /farePredictionVision HTTP/1.1\" 200 -\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import logging\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import math\n",
    "import base64\n",
    "from flask import Flask, request\n",
    "import json\n",
    "from datetime import datetime\n",
    "from datetime import datetime, timezone\n",
    "import requests\n",
    "\n",
    "from clients.vertex_ai import VertexAIClient\n",
    "from clients.google_maps import GoogleMapsClient\n",
    "from clients.natural_language import NaturalLanguageClient\n",
    "from clients.text_to_speech import TextToSpeechClient\n",
    "from clients.speech_to_text import SpeechToTextClient\n",
    "from clients.cloud_vision import CloudVisionClient\n",
    "from clients.vertex_ai_auto_ml import VertexAIAutoMLClient\n",
    "\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "project_id = os.getenv(\"GOOGLE_CLOUD_PROJECT\")\n",
    "endpoint_name = os.getenv(\"VERTEX_AI_MODEL_ENDPOINT\")\n",
    "location = os.getenv(\"LOCATION\")\n",
    "AutoML_endpoint_name = os.environ['AUTO_ML_MODEL_ENDPOINT_ID']\n",
    "\n",
    "vertex_ai_client = VertexAIClient(project_id, endpoint_name, location)\n",
    "speech_to_text_client = SpeechToTextClient()\n",
    "text_to_speech_client = TextToSpeechClient()\n",
    "natural_language_client = NaturalLanguageClient()\n",
    "google_maps_client = GoogleMapsClient()\n",
    "cloud_vision_client = CloudVisionClient()\n",
    "vertex_ai_automl_client = VertexAIAutoMLClient(project_id, AutoML_endpoint_name)\n",
    "\n",
    "#endpoint = \"https://ml-fare-prediction-120818.ue.r.appspot.com\"\n",
    "\n",
    "def haversine_distance(origin, destination):\n",
    "    \"\"\"\n",
    "    Calculate the spherical distance from coordinates\n",
    "\n",
    "    :param origin: tuple (lat, lng)\n",
    "    :param destination: tuple (lat, lng)\n",
    "    :return: Distance in km\n",
    "    \"\"\"\n",
    "    lat1, lon1 = origin\n",
    "    lat2, lon2 = destination\n",
    "    radius = 6371  # km\n",
    "\n",
    "    dlat = math.radians(lat2 - lat1)\n",
    "    dlon = math.radians(lon2 - lon1)\n",
    "    a = math.sin(dlat / 2) * math.sin(dlat / 2) + math.cos(math.radians(lat1)) * math.cos(\n",
    "        math.radians(lat2)) * math.sin(dlon / 2) * math.sin(dlon / 2)\n",
    "    c = 2 * math.atan2(math.sqrt(a), math.sqrt(1 - a))\n",
    "    d = radius * c\n",
    "\n",
    "    return d\n",
    "\n",
    "def process_test_data(raw_df):\n",
    "    \"\"\"\n",
    "    TODO: Copy your feature engineering code from task 1 here\n",
    "\n",
    "    :param raw_df: the DataFrame of the raw test data\n",
    "    :return: a DataFrame with the predictors created\n",
    "    \"\"\"\n",
    "    data_clean_test = raw_df\n",
    "   \n",
    "    # Adding new feature 'distance' between pick up and drop off location:\n",
    "    data_clean_test['distance'] = data_clean_test.apply(lambda x: haversine_distance((x['pickup_latitude'], x['pickup_longitude']),\n",
    "                                                                                       (x['dropoff_latitude'], x['dropoff_longitude'])),axis=1)\n",
    "    \n",
    "    # Extract year, month,hour and weekday from the pickup time.\n",
    "    data_clean_test['year'] = pd.to_datetime(data_clean_test['pickup_datetime'], format='%y/%m/%d %H:%M:%S').dt.year\n",
    "    data_clean_test['month'] = pd.to_datetime(data_clean_test['pickup_datetime'], format='%y/%m/%d %H:%M:%S').dt.month\n",
    "    data_clean_test['hour'] = pd.to_datetime(data_clean_test['pickup_datetime'], format='%y/%m/%d %H:%M:%S').dt.hour\n",
    "    data_clean_test['weekday'] = pd.to_datetime(data_clean_test['pickup_datetime'], format='%y/%m/%d %H:%M:%S').dt.weekday\n",
    "  \n",
    "    clean_test_df = data_clean_test.loc[:, ['distance'\n",
    "                                              ,'year','month','hour','weekday',\n",
    "                                              'pickup_latitude','pickup_longitude',\n",
    "                                              'dropoff_latitude','dropoff_longitude']]\n",
    "    return clean_test_df\n",
    "\n",
    "\n",
    "@app.route('/')\n",
    "def index():\n",
    "    return \"Hello\"\n",
    "\n",
    "\n",
    "@app.route('/predict', methods=['POST'])\n",
    "def predict():\n",
    "    raw_data_df = pd.read_json(request.data.decode('utf-8'),\n",
    "                               convert_dates=[\"pickup_datetime\"])\n",
    "    predictors_df = process_test_data(raw_data_df)\n",
    "\n",
    "    # return the predictions in the response in json format\n",
    "    return json.dumps(vertex_ai_client.predict(predictors_df.values.tolist()))\n",
    "\n",
    "@app.route('/farePrediction', methods=['POST'])\n",
    "def fare_prediction():\n",
    "    user_input = request.data\n",
    "\n",
    "    # Convert the Speech To Text\n",
    "    audio_content = user_input.decode('utf-8')\n",
    "    text_result = speech_to_text_client.recognize(content_bytes= audio_content)\n",
    "\n",
    "    # Convert the text to Entities\n",
    "    response = natural_language_client.analyze_entities(text_result)\n",
    "    final_entities = []\n",
    "    for entity in response:\n",
    "        final_entities.append(entity.name)\n",
    "    origin = final_entities[0]\n",
    "    destination = final_entities[1]\n",
    "\n",
    "    # Directions\n",
    "    directions_result = google_maps_client.directions(origin,destination)\n",
    "    start_location = {\n",
    "        \"lng\": directions_result[0]['legs'][0]['start_location']['lng'],\n",
    "        \"lat\": directions_result[0]['legs'][0]['start_location']['lat']\n",
    "    }\n",
    "\n",
    "    end_location = {\n",
    "        \"lng\": directions_result[0]['legs'][0]['end_location']['lng'],\n",
    "        \"lat\": directions_result[0]['legs'][0]['end_location']['lat']\n",
    "    }\n",
    "    dir_data = {\"start_location\": start_location, \"end_location\": end_location}\n",
    "    \n",
    "    \n",
    "    # Create Pick up and Drop off Lat and Long\n",
    "    pickup_lng = dir_data[\"start_location\"][\"lng\"]\n",
    "    pickup_lat = dir_data[\"start_location\"][\"lat\"]\n",
    "    dropoff_lng = dir_data[\"end_location\"][\"lng\"]\n",
    "    dropoff_lat = dir_data[\"end_location\"][\"lat\"]\n",
    "    \n",
    "    # Create Pick up datetime\n",
    "    pickup_time = datetime.now(timezone.utc).strftime(\"%y/%m/%d %H:%M:%S\")\n",
    "\n",
    "    # Create dataframe for fare predictions\n",
    "    raw_df = pd.DataFrame([{'pickup_latitude':pickup_lat, 'pickup_longitude':pickup_lng, 'dropoff_latitude':dropoff_lat,\n",
    "                           'dropoff_longitude':dropoff_lng,'pickup_datetime':pickup_time}])\n",
    "    \n",
    "    # Send raw df to get predictors variables\n",
    "    predictors_df = process_test_data(raw_df)\n",
    "\n",
    "    # Get Fareprediction\n",
    "    fare_response = vertex_ai_client.predict(predictors_df.values.tolist())\n",
    "\n",
    "    # Ouput Response\n",
    "    predicted_fare = \"{:.2f}\".format(fare_response[0])\n",
    "    output_text = \"Your expected fare from \"+final_entities[0]+\" to \"+final_entities[1]+\" is $\"+predicted_fare\n",
    "\n",
    "    # Text To Speech Conversion\n",
    "    response = text_to_speech_client.synthesize_speech(output_text)\n",
    "    speech = base64.b64encode(response).decode('utf-8')\n",
    "    \n",
    "    response_data = {\"predicted_fare\": predicted_fare, \n",
    "                     \"entities\": final_entities, \n",
    "                     \"text\": output_text, \n",
    "                     \"speech\": speech}\n",
    "\n",
    "    return json.dumps(response_data)\n",
    "    \n",
    "\n",
    "@app.route('/speechToText', methods=['POST'])\n",
    "def speech_to_text():\n",
    "    audio_content = request.data.decode('utf-8')\n",
    "    response_text = speech_to_text_client.recognize(content_bytes= audio_content)\n",
    "    response_data = {'text':response_text}\n",
    "    return json.dumps(response_data)\n",
    "\n",
    "@app.route('/textToSpeech', methods=['GET'])\n",
    "def text_to_speech():\n",
    "    text = request.args.get('text')\n",
    "    response = text_to_speech_client.synthesize_speech(text)\n",
    "    speech = base64.b64encode(response).decode('utf-8')\n",
    "    response_data = {'speech':speech}\n",
    "    return json.dumps(response_data)\n",
    "\n",
    "@app.route('/farePredictionVision', methods=['POST'])\n",
    "def fare_prediction_vision():\n",
    "    label_mapping = {\"Jing_Fong\": \"Jing Fong\", \"Bamonte\": \"Bamonte's\", \"Katz_Deli\": \"Katz's Delicatessen\", \"ACME\": \"ACMENYC\"}\n",
    "    \n",
    "    vision_ori_data = request.form.get('source')\n",
    "    vision_dest_data = request.form.get('destination')\n",
    "\n",
    "    # Origin location\n",
    "    vertex_ori_name = vertex_ai_automl_client.predict_image(vision_ori_data)\n",
    "    vision_ori_response = cloud_vision_client.get_landmarks(vision_ori_data)\n",
    "    if vision_ori_response is not None:\n",
    "        origin = vision_ori_response.description\n",
    "    else:\n",
    "        origin = label_mapping.get(vertex_ori_name,vertex_ori_name)\n",
    "\n",
    "    # Destination location\n",
    "    vision_dest_response = cloud_vision_client.get_landmarks(vision_dest_data)\n",
    "    vertex_dest_name = vertex_ai_automl_client.predict_image(vision_dest_data)\n",
    "    if vision_dest_response is not None:\n",
    "        destination = vision_dest_response.description\n",
    "    else:\n",
    "        destination = label_mapping.get(vertex_dest_name,vertex_dest_name)\n",
    "\n",
    "    # Directions\n",
    "    directions_result = google_maps_client.directions(origin,destination)\n",
    "    start_location = {\n",
    "        \"lng\": directions_result[0]['legs'][0]['start_location']['lng'],\n",
    "        \"lat\": directions_result[0]['legs'][0]['start_location']['lat']\n",
    "    }\n",
    "    end_location = {\n",
    "        \"lng\": directions_result[0]['legs'][0]['end_location']['lng'],\n",
    "        \"lat\": directions_result[0]['legs'][0]['end_location']['lat']\n",
    "    }\n",
    "\n",
    "    dir_data = {\"start_location\": start_location, \"end_location\": end_location}\n",
    "    \n",
    "    # Create Pick up and Drop off Lat and Long\n",
    "    pickup_lng = dir_data[\"start_location\"][\"lng\"]\n",
    "    pickup_lat = dir_data[\"start_location\"][\"lat\"]\n",
    "    dropoff_lng = dir_data[\"end_location\"][\"lng\"]\n",
    "    dropoff_lat = dir_data[\"end_location\"][\"lat\"]\n",
    "    \n",
    "    # Create Pick up datetime\n",
    "    pickup_time = datetime.now(timezone.utc).strftime(\"%y/%m/%d %H:%M:%S\")\n",
    "\n",
    "    # Create dataframe for fare predictions\n",
    "    raw_df = pd.DataFrame([{'pickup_latitude':pickup_lat, 'pickup_longitude':pickup_lng, 'dropoff_latitude':dropoff_lat,\n",
    "                           'dropoff_longitude':dropoff_lng,'pickup_datetime':pickup_time}])\n",
    "    \n",
    "    # Send raw df to get predictors variables\n",
    "    predictors_df = process_test_data(raw_df)\n",
    "\n",
    "    # Get Fareprediction\n",
    "    fare_response = vertex_ai_client.predict(predictors_df.values.tolist())\n",
    "\n",
    "    # Ouput Response\n",
    "    predicted_fare = \"{:.2f}\".format(fare_response[0])\n",
    "    output_text = \"Your expected fare from \"+origin+\" to \"+destination+\" is $\"+predicted_fare\n",
    "\n",
    "    # Text To Speech Conversion\n",
    "    response = text_to_speech_client.synthesize_speech(output_text)\n",
    "    speech = base64.b64encode(response).decode('utf-8')\n",
    "    \n",
    "    response_data = {\"predicted_fare\": predicted_fare, \n",
    "                     \"entities\": [origin,destination], \n",
    "                     \"text\": output_text, \n",
    "                     \"speech\": speech}\n",
    "\n",
    "    return json.dumps(response_data)\n",
    "\n",
    "@app.route('/namedEntities', methods=['GET'])\n",
    "def named_entities():\n",
    "    text = request.args.get('text')\n",
    "    response = natural_language_client.analyze_entities(text)\n",
    "    entities_list = []\n",
    "    for entity in response:\n",
    "        entities_list.append(entity.name)\n",
    "    response_data = {\"entities\": entities_list}\n",
    "    return json.dumps(response_data)\n",
    "\n",
    "@app.route('/directions', methods=['GET'])\n",
    "def directions():\n",
    "    origin = request.args.get('origin')\n",
    "    destination = request.args.get('destination')\n",
    "\n",
    "    directions_result = google_maps_client.directions(origin,destination)\n",
    "    start_location = {\n",
    "        \"lng\": directions_result[0]['legs'][0]['start_location']['lng'],\n",
    "        \"lat\": directions_result[0]['legs'][0]['start_location']['lat']\n",
    "    }\n",
    "\n",
    "    end_location = {\n",
    "        \"lng\": directions_result[0]['legs'][0]['end_location']['lng'],\n",
    "        \"lat\": directions_result[0]['legs'][0]['end_location']['lat']\n",
    "    }\n",
    "    response_data = {\"start_location\": start_location, \"end_location\": end_location}\n",
    "    return json.dumps(response_data)\n",
    "\n",
    "\n",
    "@app.errorhandler(500)\n",
    "def server_error(e):\n",
    "    logging.exception('An error occurred during a request.')\n",
    "    return \"\"\"\n",
    "    An internal error occurred: <pre>{}</pre>\n",
    "    See logs for full stacktrace.\n",
    "    \"\"\".format(e), 500\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "06a08436-5cce-46ba-868f-dbf2a92a642c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__'\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n",
      " * Running on http://127.0.0.1:5000\n",
      "INFO:werkzeug:\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n",
      " * Running on http://127.0.0.1:5000\n",
      "\u001b[33mPress CTRL+C to quit\u001b[0m\n",
      "INFO:werkzeug:\u001b[33mPress CTRL+C to quit\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import logging\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import math\n",
    "import base64\n",
    "from flask import Flask, request\n",
    "import json\n",
    "from datetime import datetime\n",
    "from datetime import datetime, timezone\n",
    "import requests\n",
    "\n",
    "from clients.vertex_ai import VertexAIClient\n",
    "from clients.google_maps import GoogleMapsClient\n",
    "from clients.natural_language import NaturalLanguageClient\n",
    "from clients.text_to_speech import TextToSpeechClient\n",
    "from clients.speech_to_text import SpeechToTextClient\n",
    "from clients.cloud_vision import CloudVisionClient\n",
    "from clients.vertex_ai_auto_ml import VertexAIAutoMLClient\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "project_id = os.getenv(\"GOOGLE_CLOUD_PROJECT\")\n",
    "endpoint_name = os.getenv(\"VERTEX_AI_MODEL_ENDPOINT\")\n",
    "location = os.getenv(\"LOCATION\")\n",
    "AutoML_endpoint_name = os.environ['AUTO_ML_MODEL_ENDPOINT_ID']\n",
    "\n",
    "vertex_ai_client = VertexAIClient(project_id, endpoint_name, location)\n",
    "speech_to_text_client = SpeechToTextClient()\n",
    "text_to_speech_client = TextToSpeechClient()\n",
    "natural_language_client = NaturalLanguageClient()\n",
    "google_maps_client = GoogleMapsClient()\n",
    "cloud_vision_client = CloudVisionClient()\n",
    "vertex_ai_automl_client = VertexAIAutoMLClient(project_id, AutoML_endpoint_name)\n",
    "\n",
    "endpoint = \"https://ml-fare-prediction-120818.ue.r.appspot.com\"\n",
    "\n",
    "def haversine_distance(origin, destination):\n",
    "    \"\"\"\n",
    "    Calculate the spherical distance from coordinates\n",
    "\n",
    "    :param origin: tuple (lat, lng)\n",
    "    :param destination: tuple (lat, lng)\n",
    "    :return: Distance in km\n",
    "    \"\"\"\n",
    "    lat1, lon1 = origin\n",
    "    lat2, lon2 = destination\n",
    "    radius = 6371  # km\n",
    "\n",
    "    dlat = math.radians(lat2 - lat1)\n",
    "    dlon = math.radians(lon2 - lon1)\n",
    "    a = math.sin(dlat / 2) * math.sin(dlat / 2) + math.cos(math.radians(lat1)) * math.cos(\n",
    "        math.radians(lat2)) * math.sin(dlon / 2) * math.sin(dlon / 2)\n",
    "    c = 2 * math.atan2(math.sqrt(a), math.sqrt(1 - a))\n",
    "    d = radius * c\n",
    "\n",
    "    return d\n",
    "\n",
    "def process_test_data(raw_df):\n",
    "    \"\"\"\n",
    "    TODO: Copy your feature engineering code from task 1 here\n",
    "\n",
    "    :param raw_df: the DataFrame of the raw test data\n",
    "    :return: a DataFrame with the predictors created\n",
    "    \"\"\"\n",
    "    data_clean_test = raw_df\n",
    "   \n",
    "    # Adding new feature 'distance' between pick up and drop off location:\n",
    "    data_clean_test['distance'] = data_clean_test.apply(lambda x: haversine_distance((x['pickup_latitude'], x['pickup_longitude']),\n",
    "                                                                                       (x['dropoff_latitude'], x['dropoff_longitude'])),axis=1)\n",
    "    \n",
    "    # Extract year, month,hour and weekday from the pickup time.\n",
    "    data_clean_test['year'] = pd.to_datetime(data_clean_test['pickup_datetime'], format='%y/%m/%d %H:%M:%S').dt.year\n",
    "    data_clean_test['month'] = pd.to_datetime(data_clean_test['pickup_datetime'], format='%y/%m/%d %H:%M:%S').dt.month\n",
    "    data_clean_test['hour'] = pd.to_datetime(data_clean_test['pickup_datetime'], format='%y/%m/%d %H:%M:%S').dt.hour\n",
    "    data_clean_test['weekday'] = pd.to_datetime(data_clean_test['pickup_datetime'], format='%y/%m/%d %H:%M:%S').dt.weekday\n",
    "  \n",
    "    clean_test_df = data_clean_test.loc[:, ['distance'\n",
    "                                              ,'year','month','hour','weekday',\n",
    "                                              'pickup_latitude','pickup_longitude',\n",
    "                                              'dropoff_latitude','dropoff_longitude']]\n",
    "    return clean_test_df\n",
    "\n",
    "\n",
    "@app.route('/')\n",
    "def index():\n",
    "    return \"Hello\"\n",
    "\n",
    "\n",
    "@app.route('/predict', methods=['POST'])\n",
    "def predict():\n",
    "    raw_data_df = pd.read_json(request.data.decode('utf-8'),\n",
    "                               convert_dates=[\"pickup_datetime\"])\n",
    "    predictors_df = process_test_data(raw_data_df)\n",
    "\n",
    "    # return the predictions in the response in json format\n",
    "    return json.dumps(vertex_ai_client.predict(predictors_df.values.tolist()))\n",
    "\n",
    "@app.route('/farePrediction', methods=['POST'])\n",
    "def fare_prediction():\n",
    "    user_input = request.data\n",
    "\n",
    "    # Convert the Speech To Text\n",
    "    audio_content = user_input.decode('utf-8')\n",
    "    text_result = speech_to_text_client.recognize(content_bytes= audio_content)\n",
    "\n",
    "    # Convert the text to Entities\n",
    "    response = natural_language_client.analyze_entities(text_result)\n",
    "    final_entities = []\n",
    "    for entity in response:\n",
    "        final_entities.append(entity.name)\n",
    "    origin = final_entities[0]\n",
    "    destination = final_entities[1]\n",
    "\n",
    "    # Directions\n",
    "    directions_result = google_maps_client.directions(origin,destination)\n",
    "    start_location = {\n",
    "        \"lng\": directions_result[0]['legs'][0]['start_location']['lng'],\n",
    "        \"lat\": directions_result[0]['legs'][0]['start_location']['lat']\n",
    "    }\n",
    "\n",
    "    end_location = {\n",
    "        \"lng\": directions_result[0]['legs'][0]['end_location']['lng'],\n",
    "        \"lat\": directions_result[0]['legs'][0]['end_location']['lat']\n",
    "    }\n",
    "    dir_data = {\"start_location\": start_location, \"end_location\": end_location}\n",
    "    \n",
    "    \n",
    "    # Create Pick up and Drop off Lat and Long\n",
    "    pickup_lng = dir_data[\"start_location\"][\"lng\"]\n",
    "    pickup_lat = dir_data[\"start_location\"][\"lat\"]\n",
    "    dropoff_lng = dir_data[\"end_location\"][\"lng\"]\n",
    "    dropoff_lat = dir_data[\"end_location\"][\"lat\"]\n",
    "    \n",
    "    # Create Pick up datetime\n",
    "    pickup_time = datetime.now(timezone.utc).strftime(\"%y/%m/%d %H:%M:%S\")\n",
    "\n",
    "    # Create dataframe for fare predictions\n",
    "    raw_df = pd.DataFrame([{'pickup_latitude':pickup_lat, 'pickup_longitude':pickup_lng, 'dropoff_latitude':dropoff_lat,\n",
    "                           'dropoff_longitude':dropoff_lng,'pickup_datetime':pickup_time}])\n",
    "    \n",
    "    # Send raw df to get predictors variables\n",
    "    predictors_df = process_test_data(raw_df)\n",
    "\n",
    "    # Get Fareprediction\n",
    "    fare_response = vertex_ai_client.predict(predictors_df.values.tolist())\n",
    "\n",
    "    # Ouput Response\n",
    "    predicted_fare = \"{:.2f}\".format(fare_response[0])\n",
    "    output_text = \"Your expected fare from \"+final_entities[0]+\" to \"+final_entities[1]+\" is $\"+predicted_fare\n",
    "\n",
    "    # Text To Speech Conversion\n",
    "    response = text_to_speech_client.synthesize_speech(output_text)\n",
    "    speech = base64.b64encode(response).decode('utf-8')\n",
    "    \n",
    "    response_data = {\"predicted_fare\": predicted_fare, \n",
    "                     \"entities\": final_entities, \n",
    "                     \"text\": output_text, \n",
    "                     \"speech\": speech}\n",
    "\n",
    "    return json.dumps(response_data)\n",
    "    \n",
    "\n",
    "@app.route('/speechToText', methods=['POST'])\n",
    "def speech_to_text():\n",
    "    audio_content = request.data.decode('utf-8')\n",
    "    response_text = speech_to_text_client.recognize(content_bytes= audio_content)\n",
    "    response_data = {'text':response_text}\n",
    "    return json.dumps(response_data)\n",
    "\n",
    "@app.route('/textToSpeech', methods=['GET'])\n",
    "def text_to_speech():\n",
    "    text = request.args.get('text')\n",
    "    response = text_to_speech_client.synthesize_speech(text)\n",
    "    speech = base64.b64encode(response).decode('utf-8')\n",
    "    response_data = {'speech':speech}\n",
    "    return json.dumps(response_data)\n",
    "\n",
    "@app.route('/farePredictionVision', methods=['POST'])\n",
    "def fare_prediction_vision():\n",
    "    label_mapping = {\"Jing_Fong\": \"Jing Fong\", \"Bamonte\": \"Bamonte's\", \"Katz_Deli\": \"Katz's Delicatessen\", \"ACME\": \"ACMENYC\"}\n",
    "    \n",
    "    vision_ori_data = request.form.get('source')\n",
    "    vision_dest_data = request.form.get('destination')\n",
    "\n",
    "    # Origin location\n",
    "    vision_ori_response = cloud_vision_client.get_landmarks(vision_ori_data)\n",
    "    vision_ori_name_api = vision_ori_response.description\n",
    "    vision_ori_name = next(key for key, value in label_mapping.items() if value == vision_ori_name_api)\n",
    "    vertex_ori_name = vertex_ai_automl_client.predict_image(vision_ori_data)\n",
    "    #print(vertex_ori_response1)\n",
    "    #vertex_ori_response = vision_ori_response\n",
    "    origin = vertex_ori_name if vertex_ori_name is not None else vision_ori_name\n",
    "\n",
    "    \"\"\"\n",
    "    start_location_name_api = best_ori_response.description\n",
    "    start_location_name = next(key for key, value in label_mapping.items() if value == start_location_name_api)\n",
    "    start_location = {\n",
    "        \"lng\": best_ori_response.locations[0].lat_lng.longitude,\n",
    "        \"lat\": best_ori_response.locations[0].lat_lng.latitude\n",
    "    }\n",
    "    \"\"\"\n",
    "\n",
    "    # Destination location\n",
    "    vision_dest_response = cloud_vision_client.get_landmarks(vision_dest_data)\n",
    "    vision_dest_name_api = vision_dest_response.description\n",
    "    vision_dest_name = next(key for key, value in label_mapping.items() if value == vision_dest_name_api)\n",
    "    vertex_dest_name = vertex_ai_automl_client.predict_image(vision_dest_data)\n",
    "    #vertex_dest_response = vision_dest_response\n",
    "    destination = vertex_dest_name if vertex_dest_name is not None else vision_dest_name\n",
    "\n",
    "    # Directions\n",
    "    directions_result = google_maps_client.directions(origin,destination)\n",
    "    start_location = {\n",
    "        \"lng\": directions_result[0]['legs'][0]['start_location']['lng'],\n",
    "        \"lat\": directions_result[0]['legs'][0]['start_location']['lat']\n",
    "    }\n",
    "    end_location = {\n",
    "        \"lng\": directions_result[0]['legs'][0]['end_location']['lng'],\n",
    "        \"lat\": directions_result[0]['legs'][0]['end_location']['lat']\n",
    "    }\n",
    "\n",
    "    \"\"\"\n",
    "    end_location_name_api = best_dest_response.description\n",
    "    end_location_name = next(key for key, value in label_mapping.items() if value == end_location_name_api)\n",
    "    end_location = {\n",
    "        \"lng\": best_dest_response.locations[0].lat_lng.longitude,\n",
    "        \"lat\": best_dest_response.locations[0].lat_lng.latitude\n",
    "    }\n",
    "    \"\"\"\n",
    "    dir_data = {\"start_location\": start_location, \"end_location\": end_location}\n",
    "    \n",
    "    # Create Pick up and Drop off Lat and Long\n",
    "    pickup_lng = dir_data[\"start_location\"][\"lng\"]\n",
    "    pickup_lat = dir_data[\"start_location\"][\"lat\"]\n",
    "    dropoff_lng = dir_data[\"end_location\"][\"lng\"]\n",
    "    dropoff_lat = dir_data[\"end_location\"][\"lat\"]\n",
    "    \n",
    "    # Create Pick up datetime\n",
    "    pickup_time = datetime.now(timezone.utc).strftime(\"%y/%m/%d %H:%M:%S\")\n",
    "\n",
    "    # Create dataframe for fare predictions\n",
    "    raw_df = pd.DataFrame([{'pickup_latitude':pickup_lat, 'pickup_longitude':pickup_lng, 'dropoff_latitude':dropoff_lat,\n",
    "                           'dropoff_longitude':dropoff_lng,'pickup_datetime':pickup_time}])\n",
    "    \n",
    "    # Send raw df to get predictors variables\n",
    "    predictors_df = process_test_data(raw_df)\n",
    "\n",
    "    # Get Fareprediction\n",
    "    fare_response = vertex_ai_client.predict(predictors_df.values.tolist())\n",
    "\n",
    "    # Ouput Response\n",
    "    predicted_fare = \"{:.2f}\".format(fare_response[0])\n",
    "    output_text = \"Your expected fare from \"+origin+\" to \"+destination+\" is $\"+predicted_fare\n",
    "\n",
    "    # Text To Speech Conversion\n",
    "    response = text_to_speech_client.synthesize_speech(output_text)\n",
    "    speech = base64.b64encode(response).decode('utf-8')\n",
    "    \n",
    "    response_data = {\"predicted_fare\": predicted_fare, \n",
    "                     \"entities\": [origin,destination], \n",
    "                     \"text\": output_text, \n",
    "                     \"speech\": speech}\n",
    "\n",
    "    return json.dumps(response_data)\n",
    "\n",
    "@app.route('/namedEntities', methods=['GET'])\n",
    "def named_entities():\n",
    "    text = request.args.get('text')\n",
    "    response = natural_language_client.analyze_entities(text)\n",
    "    entities_list = []\n",
    "    for entity in response:\n",
    "        entities_list.append(entity.name)\n",
    "    response_data = {\"entities\": entities_list}\n",
    "    return json.dumps(response_data)\n",
    "\n",
    "@app.route('/directions', methods=['GET'])\n",
    "def directions():\n",
    "    origin = request.args.get('origin')\n",
    "    destination = request.args.get('destination')\n",
    "\n",
    "    directions_result = google_maps_client.directions(origin,destination)\n",
    "    start_location = {\n",
    "        \"lng\": directions_result[0]['legs'][0]['start_location']['lng'],\n",
    "        \"lat\": directions_result[0]['legs'][0]['start_location']['lat']\n",
    "    }\n",
    "\n",
    "    end_location = {\n",
    "        \"lng\": directions_result[0]['legs'][0]['end_location']['lng'],\n",
    "        \"lat\": directions_result[0]['legs'][0]['end_location']['lat']\n",
    "    }\n",
    "    response_data = {\"start_location\": start_location, \"end_location\": end_location}\n",
    "    return json.dumps(response_data)\n",
    "\n",
    "\n",
    "@app.errorhandler(500)\n",
    "def server_error(e):\n",
    "    logging.exception('An error occurred during a request.')\n",
    "    return \"\"\"\n",
    "    An internal error occurred: <pre>{}</pre>\n",
    "    See logs for full stacktrace.\n",
    "    \"\"\".format(e), 500\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05a6a318-8a2f-4874-97fa-339b298dd2d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import logging\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import math\n",
    "import base64\n",
    "from flask import Flask, request\n",
    "from clients.vertex_ai import VertexAIClient\n",
    "from datetime import datetime\n",
    "from clients.google_maps import GoogleMapsClient\n",
    "from clients.natural_language import NaturalLanguageClient\n",
    "from clients.text_to_speech import TextToSpeechClient\n",
    "from clients.speech_to_text import SpeechToTextClient\n",
    "import requests\n",
    "from flask import jsonify\n",
    "import json\n",
    "from datetime import datetime, timezone\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "project_id = os.getenv(\"GOOGLE_CLOUD_PROJECT\")\n",
    "endpoint_name = os.getenv(\"VERTEX_AI_MODEL_ENDPOINT\")\n",
    "location = os.getenv(\"LOCATION\")\n",
    "\n",
    "vertex_ai_client = VertexAIClient(project_id, endpoint_name, location)\n",
    "\n",
    "endpoint = \"http://localhost:5000\"\n",
    "\n",
    "def haversine_distance(origin, destination):\n",
    "    \"\"\"\n",
    "    Calculate the spherical distance from coordinates\n",
    "\n",
    "    :param origin: tuple (lat, lng)\n",
    "    :param destination: tuple (lat, lng)\n",
    "    :return: Distance in km\n",
    "    \"\"\"\n",
    "    lat1, lon1 = origin\n",
    "    lat2, lon2 = destination\n",
    "    radius = 6371  # km\n",
    "\n",
    "    dlat = math.radians(lat2 - lat1)\n",
    "    dlon = math.radians(lon2 - lon1)\n",
    "    a = math.sin(dlat / 2) * math.sin(dlat / 2) + math.cos(math.radians(lat1)) * math.cos(\n",
    "        math.radians(lat2)) * math.sin(dlon / 2) * math.sin(dlon / 2)\n",
    "    c = 2 * math.atan2(math.sqrt(a), math.sqrt(1 - a))\n",
    "    d = radius * c\n",
    "\n",
    "    return d\n",
    "\n",
    "def process_test_data(raw_df):\n",
    "    \"\"\"\n",
    "    TODO: Copy your feature engineering code from task 1 here\n",
    "\n",
    "    :param raw_df: the DataFrame of the raw test data\n",
    "    :return: a DataFrame with the predictors created\n",
    "    \"\"\"\n",
    "    data_clean_test = raw_df\n",
    "   \n",
    "    # Adding new feature 'distance' between pick up and drop off location:\n",
    "    data_clean_test['distance'] = data_clean_test.apply(lambda x: haversine_distance((x['pickup_latitude'], x['pickup_longitude']),\n",
    "                                                                                       (x['dropoff_latitude'], x['dropoff_longitude'])),axis=1)\n",
    "    \n",
    "    # Extract year, month,hour and weekday from the pickup time.\n",
    "    data_clean_test['year'] = pd.to_datetime(data_clean_test['pickup_datetime'], format='%y/%m/%d %H:%M:%S').dt.year\n",
    "    data_clean_test['month'] = pd.to_datetime(data_clean_test['pickup_datetime'], format='%y/%m/%d %H:%M:%S').dt.month\n",
    "    data_clean_test['hour'] = pd.to_datetime(data_clean_test['pickup_datetime'], format='%y/%m/%d %H:%M:%S').dt.hour\n",
    "    data_clean_test['weekday'] = pd.to_datetime(data_clean_test['pickup_datetime'], format='%y/%m/%d %H:%M:%S').dt.weekday\n",
    "  \n",
    "    clean_test_df = data_clean_test.loc[:, ['distance'\n",
    "                                              ,'year','month','hour','weekday',\n",
    "                                              'pickup_latitude','pickup_longitude',\n",
    "                                              'dropoff_latitude','dropoff_longitude']]\n",
    "    return clean_test_df\n",
    "\n",
    "@app.route('/')\n",
    "def index():\n",
    "    return \"Hello\"\n",
    "\n",
    "@app.route('/predict', methods=['POST'])\n",
    "def predict():\n",
    "    raw_data_df = pd.read_json(request.data.decode('utf-8'),\n",
    "                               convert_dates=[\"pickup_datetime\"])\n",
    "    predictors_df = process_test_data(raw_data_df)\n",
    "\n",
    "    # return the predictions in the response in json format\n",
    "    return json.dumps(vertex_ai_client.predict(predictors_df.values.tolist()))\n",
    "\n",
    "@app.route('/farePrediction', methods=['POST'])\n",
    "def fare_prediction():\n",
    "    user_input = request.data\n",
    "\n",
    "    # Convert the Speech To Text\n",
    "    speech_to_text_response = requests.post('{}/speechToText'.format(endpoint), data=user_input)\n",
    "    speech_to_text_data = speech_to_text_response.json()\n",
    "    text_result = speech_to_text_data[\"text\"]\n",
    "\n",
    "    # Convert the text to Entities\n",
    "    entities_response = requests.get('{}/namedEntities'.format(endpoint), params={'text': text_result})\n",
    "    entities_list = entities_response.json()\n",
    "    final_entities = entities_list[\"entities\"]\n",
    "\n",
    "    # Directions\n",
    "    dir_response = requests.get('{}/directions'.format(endpoint), params={'origin': final_entities[0], 'destination': final_entities[1]})\n",
    "    dir_data = dir_response.json()\n",
    "    \n",
    "    # Fare Prediction\n",
    "    pickup_lng = dir_data[\"start_location\"][\"lng\"]\n",
    "    pickup_lat = dir_data[\"start_location\"][\"lat\"]\n",
    "    dropoff_lng = dir_data[\"end_location\"][\"lng\"]\n",
    "    dropoff_lat = dir_data[\"end_location\"][\"lat\"]\n",
    "\n",
    "    pickup_time = datetime.now(timezone.utc).strftime(\"%y/%m/%d %H:%M:%S\")\n",
    "\n",
    "    raw_df = pd.DataFrame([{'pickup_latitude':pickup_lat, 'pickup_longitude':pickup_lng, 'dropoff_latitude':dropoff_lat,\n",
    "                           'dropoff_longitude':dropoff_lng,'pickup_datetime':pickup_time}])\n",
    "    \n",
    "    #print(raw_df.to_json(orient='records'))\n",
    "    response = requests.post('{}/predict'.format(endpoint), data=raw_df.to_json(orient='records'))\n",
    "\n",
    "    # Ouput Response\n",
    "    predicted_fare = \"{:.2f}\".format(response.json()[0])\n",
    "    output_text = \"Your expected fare from \"+final_entities[0]+\" to \"+final_entities[1]+\" is $\"+predicted_fare\n",
    "    text_to_speech_response = requests.get('{}/textToSpeech'.format(endpoint), params={'text': output_text})\n",
    "    text_to_speech_data = text_to_speech_response.json()\n",
    "    response_data = {\"predicted_fare\": predicted_fare, \n",
    "                     \"entities\": final_entities, \n",
    "                     \"text\": output_text, \n",
    "                     \"speech\": text_to_speech_data['speech']}\n",
    "\n",
    "    return json.dumps(response_data)\n",
    "    \n",
    "\n",
    "@app.route('/speechToText', methods=['POST'])\n",
    "def speech_to_text():\n",
    "    speech_to_text_client = SpeechToTextClient()\n",
    "    audio_content = request.data.decode('utf-8')\n",
    "    response_text = speech_to_text_client.recognize(content_bytes= audio_content)\n",
    "    response_data = {'text':response_text}\n",
    "    return json.dumps(response_data)\n",
    "\n",
    "@app.route('/textToSpeech', methods=['GET'])\n",
    "def text_to_speech():\n",
    "    text_to_speech_client = TextToSpeechClient()\n",
    "    text = request.args.get('text')\n",
    "    response = text_to_speech_client.synthesize_speech(text)\n",
    "    speech = base64.b64encode(response).decode('utf-8')\n",
    "    response_data = {'speech':speech}\n",
    "    return json.dumps(response_data)\n",
    "\n",
    "@app.route('/farePredictionVision', methods=['POST'])\n",
    "def fare_prediction_vision():\n",
    "    pass\n",
    "\n",
    "@app.route('/namedEntities', methods=['GET'])\n",
    "def named_entities():\n",
    "    natural_language_client = NaturalLanguageClient()\n",
    "    text = request.args.get('text')\n",
    "    response = natural_language_client.analyze_entities(text)\n",
    "    entities_list = []\n",
    "    for entity in response:\n",
    "        entities_list.append(entity.name)\n",
    "    response_data = {\"entities\": entities_list}\n",
    "    return json.dumps(response_data)\n",
    "\n",
    "@app.route('/directions', methods=['GET'])\n",
    "def directions():\n",
    "    google_maps_client = GoogleMapsClient()\n",
    "    origin = request.args.get('origin')\n",
    "    destination = request.args.get('destination')\n",
    "\n",
    "    directions_result = google_maps_client.directions(origin,destination)\n",
    "    start_location = {\n",
    "        \"lng\": directions_result[0]['legs'][0]['start_location']['lng'],\n",
    "        \"lat\": directions_result[0]['legs'][0]['start_location']['lat']\n",
    "    }\n",
    "\n",
    "    end_location = {\n",
    "        \"lng\": directions_result[0]['legs'][0]['end_location']['lng'],\n",
    "        \"lat\": directions_result[0]['legs'][0]['end_location']['lat']\n",
    "    }\n",
    "    response_data = {\"start_location\": start_location, \"end_location\": end_location}\n",
    "    return json.dumps(response_data)\n",
    "\n",
    "@app.errorhandler(500)\n",
    "def server_error(e):\n",
    "    logging.exception('An error occurred during a request.')\n",
    "    return \"\"\"\n",
    "    An internal error occurred: <pre>{}</pre>\n",
    "    See logs for full stacktrace.\n",
    "    \"\"\".format(e), 500\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "567ca42f-2ce9-4d7b-9437-afcead86207e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import logging\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import math\n",
    "import base64\n",
    "from flask import Flask, request\n",
    "import json\n",
    "from datetime import datetime\n",
    "from datetime import datetime, timezone\n",
    "import requests\n",
    "\n",
    "from clients.vertex_ai import VertexAIClient\n",
    "from clients.google_maps import GoogleMapsClient\n",
    "from clients.natural_language import NaturalLanguageClient\n",
    "from clients.text_to_speech import TextToSpeechClient\n",
    "from clients.speech_to_text import SpeechToTextClient\n",
    "\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "project_id = os.getenv(\"GOOGLE_CLOUD_PROJECT\")\n",
    "endpoint_name = os.getenv(\"VERTEX_AI_MODEL_ENDPOINT\")\n",
    "location = os.getenv(\"LOCATION\")\n",
    "\n",
    "vertex_ai_client = VertexAIClient(project_id, endpoint_name, location)\n",
    "speech_to_text_client = SpeechToTextClient()\n",
    "text_to_speech_client = TextToSpeechClient()\n",
    "natural_language_client = NaturalLanguageClient()\n",
    "google_maps_client = GoogleMapsClient()\n",
    "\n",
    "endpoint = \"http://localhost:5000\"\n",
    "\n",
    "def haversine_distance(origin, destination):\n",
    "    \"\"\"\n",
    "    Calculate the spherical distance from coordinates\n",
    "\n",
    "    :param origin: tuple (lat, lng)\n",
    "    :param destination: tuple (lat, lng)\n",
    "    :return: Distance in km\n",
    "    \"\"\"\n",
    "    lat1, lon1 = origin\n",
    "    lat2, lon2 = destination\n",
    "    radius = 6371  # km\n",
    "\n",
    "    dlat = math.radians(lat2 - lat1)\n",
    "    dlon = math.radians(lon2 - lon1)\n",
    "    a = math.sin(dlat / 2) * math.sin(dlat / 2) + math.cos(math.radians(lat1)) * math.cos(\n",
    "        math.radians(lat2)) * math.sin(dlon / 2) * math.sin(dlon / 2)\n",
    "    c = 2 * math.atan2(math.sqrt(a), math.sqrt(1 - a))\n",
    "    d = radius * c\n",
    "\n",
    "    return d\n",
    "\n",
    "def process_test_data(raw_df):\n",
    "    \"\"\"\n",
    "    TODO: Copy your feature engineering code from task 1 here\n",
    "\n",
    "    :param raw_df: the DataFrame of the raw test data\n",
    "    :return: a DataFrame with the predictors created\n",
    "    \"\"\"\n",
    "    data_clean_test = raw_df\n",
    "   \n",
    "    # Adding new feature 'distance' between pick up and drop off location:\n",
    "    data_clean_test['distance'] = data_clean_test.apply(lambda x: haversine_distance((x['pickup_latitude'], x['pickup_longitude']),\n",
    "                                                                                       (x['dropoff_latitude'], x['dropoff_longitude'])),axis=1)\n",
    "    \n",
    "    # Extract year, month,hour and weekday from the pickup time.\n",
    "    data_clean_test['year'] = pd.to_datetime(data_clean_test['pickup_datetime'], format='%y/%m/%d %H:%M:%S').dt.year\n",
    "    data_clean_test['month'] = pd.to_datetime(data_clean_test['pickup_datetime'], format='%y/%m/%d %H:%M:%S').dt.month\n",
    "    data_clean_test['hour'] = pd.to_datetime(data_clean_test['pickup_datetime'], format='%y/%m/%d %H:%M:%S').dt.hour\n",
    "    data_clean_test['weekday'] = pd.to_datetime(data_clean_test['pickup_datetime'], format='%y/%m/%d %H:%M:%S').dt.weekday\n",
    "  \n",
    "    clean_test_df = data_clean_test.loc[:, ['distance'\n",
    "                                              ,'year','month','hour','weekday',\n",
    "                                              'pickup_latitude','pickup_longitude',\n",
    "                                              'dropoff_latitude','dropoff_longitude']]\n",
    "    return clean_test_df\n",
    "\n",
    "\n",
    "@app.route('/')\n",
    "def index():\n",
    "    return \"Hello\"\n",
    "\n",
    "\n",
    "@app.route('/predict', methods=['POST'])\n",
    "def predict():\n",
    "    raw_data_df = pd.read_json(request.data.decode('utf-8'),\n",
    "                               convert_dates=[\"pickup_datetime\"])\n",
    "    predictors_df = process_test_data(raw_data_df)\n",
    "\n",
    "    # return the predictions in the response in json format\n",
    "    return json.dumps(vertex_ai_client.predict(predictors_df.values.tolist()))\n",
    "\n",
    "@app.route('/farePrediction', methods=['POST'])\n",
    "def fare_prediction():\n",
    "    user_input = request.data\n",
    "\n",
    "    # Convert the Speech To Text\n",
    "    audio_content = user_input.decode('utf-8')\n",
    "    text_result = speech_to_text_client.recognize(content_bytes= audio_content)\n",
    "\n",
    "    # Convert the text to Entities\n",
    "    response = natural_language_client.analyze_entities(text_result)\n",
    "    final_entities = []\n",
    "    for entity in response:\n",
    "        final_entities.append(entity.name)\n",
    "    origin = final_entities[0]\n",
    "    destination = final_entities[1]\n",
    "\n",
    "    # Directions\n",
    "    directions_result = google_maps_client.directions(origin,destination)\n",
    "    start_location = {\n",
    "        \"lng\": directions_result[0]['legs'][0]['start_location']['lng'],\n",
    "        \"lat\": directions_result[0]['legs'][0]['start_location']['lat']\n",
    "    }\n",
    "\n",
    "    end_location = {\n",
    "        \"lng\": directions_result[0]['legs'][0]['end_location']['lng'],\n",
    "        \"lat\": directions_result[0]['legs'][0]['end_location']['lat']\n",
    "    }\n",
    "    dir_data = {\"start_location\": start_location, \"end_location\": end_location}\n",
    "    \n",
    "    \n",
    "    # Create Pick up and Drop off Lat and Long\n",
    "    pickup_lng = dir_data[\"start_location\"][\"lng\"]\n",
    "    pickup_lat = dir_data[\"start_location\"][\"lat\"]\n",
    "    dropoff_lng = dir_data[\"end_location\"][\"lng\"]\n",
    "    dropoff_lat = dir_data[\"end_location\"][\"lat\"]\n",
    "    \n",
    "    # Create Pick up datetime\n",
    "    pickup_time = datetime.now(timezone.utc).strftime(\"%y/%m/%d %H:%M:%S\")\n",
    "\n",
    "    # Create dataframe for fare predictions\n",
    "    raw_df = pd.DataFrame([{'pickup_latitude':pickup_lat, 'pickup_longitude':pickup_lng, 'dropoff_latitude':dropoff_lat,\n",
    "                           'dropoff_longitude':dropoff_lng,'pickup_datetime':pickup_time}])\n",
    "    \n",
    "    # Send raw df to get predictors variables\n",
    "    predictors_df = process_test_data(raw_df)\n",
    "\n",
    "    # Get Fareprediction\n",
    "    fare_response = vertex_ai_client.predict(predictors_df.values.tolist())\n",
    "\n",
    "    # Ouput Response\n",
    "    predicted_fare = \"{:.2f}\".format(fare_response[0])\n",
    "    output_text = \"Your expected fare from \"+final_entities[0]+\" to \"+final_entities[1]+\" is $\"+predicted_fare\n",
    "\n",
    "    # Text To Speech Conversion\n",
    "    response = text_to_speech_client.synthesize_speech(output_text)\n",
    "    speech = base64.b64encode(response).decode('utf-8')\n",
    "    \n",
    "    response_data = {\"predicted_fare\": predicted_fare, \n",
    "                     \"entities\": final_entities, \n",
    "                     \"text\": output_text, \n",
    "                     \"speech\": speech}\n",
    "    print(\"Final Response: \",response_data)\n",
    "\n",
    "    return json.dumps(response_data)\n",
    "    \n",
    "\n",
    "@app.route('/speechToText', methods=['POST'])\n",
    "def speech_to_text():\n",
    "    audio_content = request.data.decode('utf-8')\n",
    "    response_text = speech_to_text_client.recognize(content_bytes= audio_content)\n",
    "    response_data = {'text':response_text}\n",
    "    return json.dumps(response_data)\n",
    "\n",
    "@app.route('/textToSpeech', methods=['GET'])\n",
    "def text_to_speech():\n",
    "    text = request.args.get('text')\n",
    "    response = text_to_speech_client.synthesize_speech(text)\n",
    "    speech = base64.b64encode(response).decode('utf-8')\n",
    "    response_data = {'speech':speech}\n",
    "    return json.dumps(response_data)\n",
    "\n",
    "@app.route('/farePredictionVision', methods=['POST'])\n",
    "def fare_prediction_vision():\n",
    "    pass\n",
    "\n",
    "@app.route('/namedEntities', methods=['GET'])\n",
    "def named_entities():\n",
    "    text = request.args.get('text')\n",
    "    response = natural_language_client.analyze_entities(text)\n",
    "    entities_list = []\n",
    "    for entity in response:\n",
    "        entities_list.append(entity.name)\n",
    "    response_data = {\"entities\": entities_list}\n",
    "    return json.dumps(response_data)\n",
    "\n",
    "@app.route('/directions', methods=['GET'])\n",
    "def directions():\n",
    "    origin = request.args.get('origin')\n",
    "    destination = request.args.get('destination')\n",
    "\n",
    "    directions_result = google_maps_client.directions(origin,destination)\n",
    "    start_location = {\n",
    "        \"lng\": directions_result[0]['legs'][0]['start_location']['lng'],\n",
    "        \"lat\": directions_result[0]['legs'][0]['start_location']['lat']\n",
    "    }\n",
    "\n",
    "    end_location = {\n",
    "        \"lng\": directions_result[0]['legs'][0]['end_location']['lng'],\n",
    "        \"lat\": directions_result[0]['legs'][0]['end_location']['lat']\n",
    "    }\n",
    "    response_data = {\"start_location\": start_location, \"end_location\": end_location}\n",
    "    return json.dumps(response_data)\n",
    "\n",
    "\n",
    "@app.errorhandler(500)\n",
    "def server_error(e):\n",
    "    logging.exception('An error occurred during a request.')\n",
    "    return \"\"\"\n",
    "    An internal error occurred: <pre>{}</pre>\n",
    "    See logs for full stacktrace.\n",
    "    \"\"\".format(e), 500\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "933093a7-7ba5-4e75-9392-0d1a98dd77ab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
