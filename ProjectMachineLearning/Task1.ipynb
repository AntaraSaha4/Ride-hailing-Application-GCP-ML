{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "excluded_from_script"
    ],
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Machine Learning Project, Task 1: Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import math\n",
    "import numpy as np\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from xgboost.sklearn import XGBRegressor\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "excluded_from_script"
    ],
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Utility Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def haversine_distance(origin, destination):\n",
    "    \"\"\"\n",
    "    # Formula to calculate the spherical distance between 2 coordinates, with each specified as a (lat, lng) tuple\n",
    "\n",
    "    :param origin: (lat, lng)\n",
    "    :type origin: tuple\n",
    "    :param destination: (lat, lng)\n",
    "    :type destination: tuple\n",
    "    :return: haversine distance\n",
    "    :rtype: float\n",
    "    \"\"\"\n",
    "    lat1, lon1 = origin\n",
    "    lat2, lon2 = destination\n",
    "    radius = 6371  # km\n",
    "\n",
    "    dlat = math.radians(lat2 - lat1)\n",
    "    dlon = math.radians(lon2 - lon1)\n",
    "    a = math.sin(dlat / 2) * math.sin(dlat / 2) + math.cos(math.radians(lat1)) * math.cos(\n",
    "        math.radians(lat2)) * math.sin(dlon / 2) * math.sin(dlon / 2)\n",
    "    c = 2 * math.atan2(math.sqrt(a), math.sqrt(1 - a))\n",
    "    d = radius * c\n",
    "\n",
    "    return d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "excluded_from_script"
    ],
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Feature Engineering\n",
    "> TODO: You need to implement the two functions below to take in raw data, perform data preprocessing and create new features using your knowledge of the problem domain. The main difference between processing test and training data is that **you cannot filter out records from the test set** (i.e., you have to return a prediction even if the input data may be an outlier).\n",
    "\n",
    "> Feel free to add additional cells to explore the data. You will also find it very helpful to visualize the distribution of the dataset to get a sense of the trends or patterns. **However, you will want to exclude these cells when we export the notebook as an executable.** The submitter will exclude any cells tagged with `excluded_from_script`, so make sure you tag any cells containing exploration code appropriately. You can display the tags for each cell as such: `View > Cell Toolbar > Tags`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def process_train_data(raw_df):\n",
    "    \"\"\"\n",
    "    TODO: Implement this method.\n",
    "    \n",
    "    You may drop rows if needed.\n",
    "\n",
    "    :param raw_df: the DataFrame of the raw training data\n",
    "    :return:  a DataFrame with the predictors created\n",
    "    \"\"\"\n",
    "    return raw_df\n",
    "\n",
    "\n",
    "def process_test_data(raw_df):\n",
    "    \"\"\"\n",
    "    TODO: Implement this method.\n",
    "    \n",
    "    You should NOT drop any rows.\n",
    "\n",
    "    :param raw_df: the DataFrame of the raw test data\n",
    "    :return: a DataFrame with the predictors created\n",
    "    \"\"\"\n",
    "    return raw_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "excluded_from_script"
    ],
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Model Checking with XGBoost and k-fold Cross Validation\n",
    "> As you iterate on your features, you want to quickly validate the model and evaluate if these new features help to improve your model's predictions. This process is known as model checking. You will use XGBoost to train the model, and use Root Mean Squared Error (RMSE) to quantify the performance. Cross validation is used to evaluate how the performance of the model will generalize to an unseen dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Load data\n",
    "raw_train = pd.read_csv('data/cc_nyc_fare_train_small.csv', parse_dates=['pickup_datetime'])\n",
    "print('Shape of the raw data: {}'.format(raw_train.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Transform features using the function you have defined\n",
    "df_train = process_train_data(raw_train)\n",
    "\n",
    "# Remove fields that we do not want to train with\n",
    "X = df_train.drop(['key', 'fare_amount', 'pickup_datetime'], axis=1, errors='ignore')\n",
    "\n",
    "# Extract the value you want to predict\n",
    "Y = df_train['fare_amount']\n",
    "print('Shape of the feature matrix: {}'.format(X.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "excluded_from_script"
    ],
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Evaluate features with K-fold cross validation\n",
    "# The higher K is, the longer it takes to run, and the higher your confidence in the score\n",
    "K = 5\n",
    "model = XGBRegressor(objective ='reg:squarederror')\n",
    "scores = cross_val_score(model, X, Y, cv=K, scoring='neg_mean_squared_error', verbose=False)\n",
    "avg_rmse = math.sqrt(abs(np.mean(scores)))\n",
    "\n",
    "print('Average RMSE with {}-fold Cross Validation: {:.3f}'.format(K, avg_rmse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "excluded_from_script"
    ],
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Evaluating Feature Importance\n",
    "> After you train the model, XGBoost has a handy utility that allows you to compare the relative importance of each feature. You should use this to assess which features you created are meaningful. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "excluded_from_script"
    ],
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Train the model again with the entire training set\n",
    "model = XGBRegressor(objective ='reg:squarederror')\n",
    "model.fit(X, Y)\n",
    "xgb.plot_importance(model, height=0.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "excluded_from_script"
    ],
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Evaluating against Hidden Test Set\n",
    "> Once you are satisfied with the performance of the features you have selected, you can use the trained model to make predictions on the hidden test set. **Do not change the default configuration of the model.** In task 1, you want to focus on feature selection, without worrying about tuning the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Build final model with the entire training set\n",
    "final_model = XGBRegressor(objective ='reg:squarederror')\n",
    "final_model.fit(X, Y)\n",
    "\n",
    "# Read and transform test set\n",
    "raw_test = pd.read_csv('data/cc_nyc_fare_test.csv', parse_dates=['pickup_datetime'])\n",
    "df_test = process_test_data(raw_test)\n",
    "X_test = df_test.drop(['key', 'pickup_datetime'], axis=1, errors='ignore')\n",
    "\n",
    "# Make predictions for test set and output a csv file\n",
    "# DO NOT change the column names\n",
    "df_test['predicted_fare_amount'] = final_model.predict(X_test)\n",
    "df_test[['key', 'predicted_fare_amount']].to_csv('predictions.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}